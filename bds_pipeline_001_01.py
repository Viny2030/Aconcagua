# -*- coding: utf-8 -*-
"""bds-pipeline-001-01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/cristiandarioortegayubro/767501b3a8c383730038fbf658b57486/bds-pipeline-001-01.ipynb

<p align="center">
<img src="https://github.com/cristiandarioortegayubro/BDS/blob/main/images/Logo%20Scikit-learn.png?raw=true">
</p>

# **<font color="DeepPink">Historia de scikit-learn</font>**

<p align="justify">
La historia de scikit-learn es interesante, ya que se ha convertido en una de las bibliotecas de aprendizaje autom√°tico m√°s populares y ampliamente utilizadas en el ecosistema de Python.
<br><br>
üëÄ Resumen de su historia:
<br><br>
<ol align="justify">
<li>
<b>Or√≠genes y lanzamiento inicial:</b>
   Scikit-learn fue creado por David Cournapeau en 2007 como parte de su tesis doctoral en la Universidad Tecnol√≥gica de Nueva Gales del Sur, en Australia. Originalmente, la biblioteca se llamaba "scikits.learn" y se dise√±√≥ como un proyecto de c√≥digo abierto para proporcionar herramientas simples y eficientes para el aprendizaje autom√°tico en Python. La primera versi√≥n p√∫blica fue lanzada en el a√±o 2010.
</li>
<li>
<b>Crecimiento y adopci√≥n:</b>
   Desde su lanzamiento inicial, scikit-learn ha experimentado un crecimiento significativo en t√©rminos de funcionalidad, rendimiento y popularidad. Se han agregado numerosos algoritmos de aprendizaje autom√°tico, herramientas de preprocesamiento de datos, m√©tricas de evaluaci√≥n y utilidades para facilitar el desarrollo de modelos predictivos y an√°lisis de datos.
</li>
<li>
<b>Contribuciones y comunidad:</b>
   Una de las fortalezas de scikit-learn es su activa comunidad de desarrolladores y contribuyentes. A lo largo de los a√±os, cientos de desarrolladores han contribuido al proyecto, a√±adiendo nuevas caracter√≠sticas, corrigiendo errores y mejorando la documentaci√≥n. Esto ha permitido que scikit-learn evolucione r√°pidamente y se mantenga al d√≠a con los avances en el campo del aprendizaje autom√°tico.
</li>
<li>
<b>Reconocimiento y uso generalizado:</b>
   Scikit-learn ha sido ampliamente reconocido en la comunidad de aprendizaje autom√°tico por su facilidad de uso, su enfoque en la simplicidad y su amplia gama de algoritmos implementados. Se ha convertido en una herramienta est√°ndar para estudiantes, acad√©micos, investigadores y profesionales de la industria que trabajan en aprendizaje autom√°tico y an√°lisis de datos.
</li>
<li>
<b>Integraci√≥n con ecosistema de Python:</b>
   Scikit-learn se integra bien con otras bibliotecas y herramientas populares en el ecosistema de Python, como NumPy, SciPy, Pandas, Matplotlib, Seaborn y Plotly lo que permite construir y desplegar flujos de trabajo completos para el an√°lisis de datos y el desarrollo de modelos predictivos.
</li>
</ol>
<br>
<p align="justify">
‚úÖ La historia de scikit-learn es la de un proyecto de c√≥digo abierto que ha crecido desde sus humildes comienzos hasta convertirse en una de las bibliotecas de aprendizaje autom√°tico m√°s utilizadas y respetadas en la comunidad de Python. Su simplicidad, funcionalidad y comunidad activa han contribuido en gran medida a su √©xito y adopci√≥n generalizada.

# **<font color="DeepPink">Primer modelo con scikit-learn</font>**

‚ù§ https://scikit-learn.org/stable/

<p align="justify">
üëÄ En este Colab, vamos a construir un modelo predictivo de datos tabulares y solo con las variables num√©ricas. <br><br>En particular, se destacan las siguientes funciones y m√©todos:
</p>

- <code>.fit(X, y)</code> para entrenar.
- <code>.predict(X)</code> para predecir.
- <code>.score(X, y)</code> para evaluar la predicci√≥n.
- Evaluaci√≥n del rendimiento del modelo con:
     - un conjunto de datos de entrenamiento.
     - un conjunto de datos de prueba.

<p align="justify"> üëÄ Los <mark>datos num√©ricos</mark> son el tipo de datos que <mark>se utilizan naturalmente en los modelos de aprendizaje autom√°tico</mark> y pueden incorporarse directamente a los modelos predictivos, bueno, casi directamente (conviene normalizarlos).<br><br> Ahora a continuaci√≥n, vamos a cargar un conjunto de  datos, pero solo vamos a trabajar con las columnas num√©ricas. Por eso, habilitamos <code>Pandas</code>, <code>Numpy</code> y leemos los datos de <code>Github</code>.</p>
"""

import numpy as np
import pandas as pd

adult_census = pd.read_csv("https://raw.githubusercontent.com/cristiandarioortegayubro/BDS/main/datasets/adult_census.csv")

adult_census

"""<p align="justify">
üëÄ Vamos a trabajar con los datos del censo.
</p>

Las columnas son:

- Edad - Age
- Clase de Trabajo - Workclass
- Educacion - Education
- Educacion numerica - Education num
- Estado civil - Marital status
- Ocupacion - Occupation
- Relacion - Relationship
- Raza - Race
- Sexo - Sex
- Ganancia de capital - Capital gain
- Perdida de capital - Capital loss
- Horas por semana - Hours per week
- Pais nativo - Native country
- Clase - Class
"""

adult_census.info()

"""<p align="justify">
üëÄ Asignamos a un objeto la variable objetivo:
</p>

"""

target_column = "class"

"""<p align="justify">
üëÄ Generamos la lista de las variables (columnas) numericas.
</p>

"""

numerical_columns = ["age",
                     "education-num",
                     "capital-gain",
                     "capital-loss",
                     "hours-per-week"]

"""<p align="justify">
üëÄ Las columnas num√©ricas y la variable objetivo.
</p>
"""

all_columns = numerical_columns + [target_column]

all_columns

df = adult_census[all_columns]

"""üëÄ Ahora si, nuestro <code>DataFrame</code> de columnas num√©ricas..., excepto la variable objetivo que no es num√©rica..."""

df.describe().T.round(2)

df

df.dtypes

"""<p align="justify">
‚úÖ El objetivo con estos datos es predecir si una persona gana m√°s de 50K al a√±o a partir de las variables que se encuentran a disposici√≥n.
</p>

# **<font color="DeepPink">Algunos conceptos de Aprendizaje Autom√°tico</font>**

<p align="justify">
‚úÖ En general, un problema de <b>Aprendizaje Autom√°tico</b> considera un conjunto de $n$ muestras de datos y luego trata de predecir las propiedades de los datos desconocidos. Si cada muestra es m√°s que un solo n√∫mero, por ejemplo los datos multivariados, se dice que la muestra tiene varios atributos o caracter√≠sticas.
<br><br> Vamos a dividir los problemas de Aprendizaje Autom√°tico en dos categor√≠as:
<br><br>
</p>
<ul align="justify">
<li>
<b>Aprendizaje Supervisado</b>, en el que los datos vienen con atributos adicionales que queremos predecir. El Aprendizaje Supervisado puede ser de:
<ul><li>
<b>Clasificaci√≥n</b>: las muestras pertenecen a dos (clasificacion binaria) o m√°s clases (clasificacion multiclase) y queremos aprender de los datos ya etiquetados (variable objetivo) para predecir la clase de aquellos datos que no estan etiquetados (datos nuevos). Un ejemplo de un problema de clasificaci√≥n binaria ser√≠a la predicci√≥n de la contrataci√≥n de un seguro ofrecido por un banco, en virtud de las caracteristicas de los clientes del banco.
</li>
<li>
<b>Regresi√≥n</b>: si la salida deseada consiste en una o m√°s variables continuas, entonces este modelo se llama regresi√≥n. Un ejemplo de un problema de regresi√≥n ser√≠a la predicci√≥n del precio de una propiedad en virtud de las caracteristicas de la propiedad.
</li></ul><br>
<li>
<b>Aprendizaje no Supervisado</b>, en el que los datos de entrenamiento consisten en un conjunto de vectores de entrada $x$ sin ninguna variable objetivo correspondiente, ya que el objetivo de tales problemas de Aprendizaje no Supervisado puede ser descubrir grupos de ejemplos similares dentro de los datos, lo que se denomina agrupamiento, o determinar la distribuci√≥n de los datos, conocido como estimaci√≥n de densidad, o proyectar los datos desde un punto de vista de dimensi√≥n, como por ejemplo, reducir el espacio a dos o tres dimensiones con el prop√≥sito de visualizaci√≥n.

<p align="center">
<img src="https://github.com/cristiandarioortegayubro/BDS/blob/main/images/ML-001.png?raw=true" width="500">
</p>

# **<font color="DeepPink">Separar la variable objetivo y las variables explicativas</font>**

üëÄ Ahora vamos a dividir del conjunto de datos, la variable objetivo y las variables explicativas, es decir, vamos a obtener una <code>Serie</code> para la variable objetivo y un <code>DataFrame</code> con las variables explicativas...

## **<font color="DeepPink">Variable objetivo</font>**
"""

y = df[target_column]
y

"""üëÄ Verificamos que el objeto es una <code>Serie</code>..."""

y.shape

type(y)

""" ## **<font color="DeepPink">Variables explicativas</font>**"""

X = df.drop(columns=["class"])
X

"""üëÄ Verificamos que el objeto es un <code>DataFrame</code>..."""

type(X)

"""üëÄ Todas las columnas del <code>DataFrame</code> son num√©ricas..."""

X.dtypes

X.shape

print("")
print(f"El conjunto de datos contiene {X.shape[0]} registros y "
      f"{X.shape[1]} variables explicativas")

"""# **<font color="DeepPink">Ajustar un modelo y hacer predicciones</font>**

‚ù§ https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html

<p align="justify">
üëÄ Construiremos un modelo de clasificaci√≥n binaria usando el algoritmo de <code>regresi√≥n log√≠stica</code>.
</p>
"""

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
_ = model.fit(X, y)

"""<p align="justify">
La l√≠nea de c√≥digo se divide en dos partes:
<br><br>

1. `model = LogisticRegression()`

<p align="justify">
üëÄ Esta primera parte crea una instancia de la clase <code>LogisticRegression</code> de scikit-learn. <mark>Esto significa que se est√° creando un modelo de regresi√≥n log√≠stica</mark> que puede ser utilizado para predecir valores futuros.
</p>

2. `_ = model.fit(X, y)`

<p align="justify">
La segunda parte del c√≥digo entrena el modelo de regresi√≥n log√≠stica utilizando los datos de entrenamiento <code>X</code> y <code>y</code>. La variable <code>_</code> se utiliza para indicar que no se necesita el valor de retorno de la funci√≥n <code>fit</code>. La funci√≥n <code>fit</code> actualiza los par√°metros del modelo de regresi√≥n log√≠stica para que se ajusten mejor a los datos de entrenamiento.
<br><br>
En resumen, el script crea un modelo de regresi√≥n log√≠stica y lo entrena utilizando los datos de entrenamiento <code>X</code> y <code>y</code>. La variable <code>_</code> se utiliza para indicar que no se necesita el valor de retorno de la funci√≥n <code>fit</code>.
<br><br>
üíñ Aqu√≠ hay algunos detalles adicionales sobre el script:
<br><br>

* El modelo de regresi√≥n log√≠stica es un modelo de aprendizaje autom√°tico que se utiliza para predecir valores binarios (es decir, 0 o 1).
* La funci√≥n `fit` actualiza los par√°metros del modelo de regresi√≥n log√≠stica utilizando el algoritmo de optimizaci√≥n de m√°xima verosimilitud.

<p align="justify">
üëÄ El m√©todo <code>fit</code> que vamos a utilizar, se compone de dos elementos:
</p>

- Un algoritmo de aprendizaje, y
- Algunos estados de los modelos.

<br>
<p align="justify">
El algoritmo de aprendizaje toma el conjunto de datos de entrenamiento y la variable objetivo de entrenamiento como entrada, es decir como <code>input</code> y establece los estados del modelo. Estos estados de los modelos se usar√°n m√°s tarde para predecir (para clasificadores y regresores)
o para transformar datos (para transformadores). <br><br>Tanto el algoritmo de aprendizaje como el tipo de estado del modelo son espec√≠ficos de cada modelo.
</p>

<p align="justify">
üëÄ Ahora bien, para predecir un modelo se utiliza una funci√≥n de predicci√≥n. El m√©todo que se utiliza es <code>predict()</code>.
</p>
"""

target_predicted = model.predict(X)

type(target_predicted)

"""<p align="justify">
üëÄ Ahora observamos las predicciones generadas. Solo veremos las primeras 10  predicciones...
</p>

"""

target_predicted[:10]

"""üëÄ Y vemos los datos reales..."""

y[:10]

"""üëÄ Y comparamos los datos reales, con las predicciones, solo para las primeras 10 muestras..."""

y[:10] == target_predicted[:10]

"""üëÄ Y podemos ver cuantas predicciones son correctas para estas 10 muestras..."""

print("")
print(f"N√∫mero de predicciones correctas: "
      f"{(y[:10] == target_predicted[:10]).sum()} / 10")

"""üëÄ Y podemos calcular la media de las predicciones correctas..."""

y.shape

(y == target_predicted).mean().round(4)

model.score(X, y).round(4)

"""<p align="justify">
üëÄ Este resultado significa que el modelo hace una predicci√≥n correcta para aproximadamente $81$ muestras de $100$ muestras. Hay que tener en cuenta que usamos los mismos datos para entrenar y para evaluar el modelo. ¬øSe puede confiar en esta evaluaci√≥n, o esta evaluaci√≥n es demasiado buena para ser verdad?.
<br><br>Para poder responder esa interrogante, en vez de trabajar con todas las muestras, vamos a dividir nuestros datos en un conjunto de datos de entrenamiento y un conjunto de datos de prueba...
</p>

# **<font color="DeepPink">Divisi√≥n de datos de entrenamiento y prueba</font>**

<p align="justify">
üëÄ Al construir un modelo de aprendizaje autom√°tico, es importante evaluar el modelo entrenado en datos que no se usaron para ajustarlo <code>fit</code>, ya que la generalizaci√≥n de un modelo es m√°s que la memorizaci√≥n.
<br><br>
Esto significa que queremos un modelo de aprendizaje que generalice a nuevos datos, y no un modelo que compara con los datos que memorizamos.
<br><br>
Es m√°s dif√≠cil concluir sobre casos nunca vistos, que concluir sobre los casos que ya hemos vistos. Por este motivo, es que se plantea una divisi√≥n de los datos disponibles.
<br><br>
Por ese motivo, los datos utilizados para ajustar un modelo se denominan datos de entrenamiento, mientras que los datos utilizados para evaluar un modelo se denominan datos de prueba, es decir, dividimos el conjunto de datos en un conjunto de datos de entrenamiento y un conjunto de datos de prueba.
</p>

üëÄ Nuestro <code>DataFrame</code> tiene las siguientes dimensiones...
"""

df.shape

int(48842*0.2)

"""üëÄ Vamos a tomar una muestra de 9768 muestras (indices) y luego vamos a resetear el indice de nuestro <code>DataFrame</code> con el m√©todo <code>reset_index()</code>. A destacar, usamos el par√°metro <code>random_state</code> para ajustar la pseudoalietoriedad de la selecci√≥n de las muestras...
<br><br>
Este valor es aproximadamente el $20$% de las muestras del <code>DataFrame</code>...
"""

df_test = df.sample(9768, random_state=123)

df_test.shape

round((df_test.shape[0]/df.shape[0]),3)

"""üëÄ Ahora vamos a sacar del <code>DataFrame</code> el conjunto de datos de prueba..."""

df_test.head()

df_train = df.drop(index=df_test.index)

round((df_train.shape[0]/df.shape[0]),3)

"""üëÄ y reseteamos los indices de los dos conjuntos de datos..."""

df_test.reset_index(drop=True, inplace=True)
df_train.reset_index(drop=True, inplace=True)

"""üëÄ Ahora tenemos un <code>DataFrame</code> de testeo..."""

df_test

df_test.shape

"""üëÄ Y tenemos un <code>DataFrame</code> sin los datos de la muestra..."""

df_train

df_train.shape

"""üëÄ De este <code>DataFrame</code> de testeo, separamos en variable objetivo y vector de caracteristicas, la variable objetivo es nuestra $y$, el vector de caracteristicas es nuestro $X$..."""

y_test = df_test["class"]
X_test = df_test.drop(columns=["class"])

y_test.shape

X_test.shape

print("")
print(f"El conjunto de prueba contiene {X_test.shape[0]} registros y "
      f"{X.shape[1]} variables explicativas.")

"""üëÄ Hacemos lo mismo con el conjunto de datos..."""

y_train = df_train["class"]
X_train = df_train.drop(columns=["class"])

print("")
print(f"El conjunto de prueba contiene {X_train.shape[0]} registros y "
      f"{X.shape[1]} variables explicativas.")

"""<p align="justify">
üëÄ En lugar de calcular la predicci√≥n y calcular manualmente la tasa de √©xito promedio de esa predicci√≥n, podemos usar la puntuaci√≥n del m√©todo. Cuando se trata de clasificadores, este m√©todo devuelve su m√©trica de rendimiento.
</p>

"""

model = LogisticRegression()
_ = model.fit(X_train, y_train)

model

accuracy = model.score(X_test, y_test).round(4)
accuracy

"""üëÄ El nombre del modelo es..."""

model_name = model.__class__.__name__
model_name

print("")
print(f"El accuracy del modelo {model_name} es "
      f"{accuracy:.4f}")

"""<p align="justify">
üëÄ Para calcular la puntuaci√≥n de la m√©trica, el predictor primero calcula las predicciones (usando el m√©todo de predicci√≥n) y luego usa una funci√≥n de puntuaci√≥n para comparar la variable objetivo real y las predicciones realizadas. Finalmente, se devuelve la puntuaci√≥n obtenida en virtud de los aciertos en las predicciones.<br><br>Por lo tanto, es importante probar siempre el rendimiento de generalizaci√≥n de los modelos predictivos en un conjunto diferente al utilizado para entrenar los modelos, en este caso en el conjunto de prueba.
</p>

"""

model.score(X, y).round(4)

model.score(X_test, y_test).round(4)

"""# **<font color="DeepPink">Conclusiones</font>**

<p align="justify">
üëÄ En este colab nosotros:
<br><br>
‚úÖ Cargamos los datos de un archivo <code>CSV</code> usando <code>Pandas</code>.<br>
‚úÖ Examinamos las variables num√©ricas.
<br>  
‚úÖ Hicimos un modelo con todo el conjunto de datos.
<br>
‚úÖ Tambien generamos un conjunto de datos de prueba para evaluar.</p>

<br>
<br>
<p align="center"><b>
üíó
<font color="DeepPink">
Hemos llegado al final de nuestro colab, a seguir codeando...
</font>
</p>
"""